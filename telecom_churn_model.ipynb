{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "data = pd.read_csv('/Users/tamielnaicker/Desktop/Telecom Customer Churn/telecom_customer_churn.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. All-In-One EDA (Pandas Profiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, explorative= True)\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Types (encoding?) \n",
    "data_types = data.dtypes\n",
    "print(data_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise distribution of target variable ('Customer Status')\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'Customer Status', data = data)\n",
    "plt.title('Distribtuion of Customer Status')\n",
    "plt.xlabel('Customer Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore correlations between numerical features\n",
    "plt.figure(figsize=(12,8))\n",
    "correlation_matrix = data.corr()\n",
    "sns.heatmap(correlation_matrix, annot = True, cmap = 'coolwarm', fmt = \".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationships between: \n",
    "\n",
    "#1. Total Charges & Total Revenue (0.97)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x = 'Total Charges', y = 'Total Revenue')\n",
    "plt.title('Scatter Plot: Total Charges vs Total Revenue')\n",
    "plt.show\n",
    "\n",
    "#2. Tenure in Months & Total Revenue (0.85)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x = 'Tenure in Months', y = 'Total Revenue')\n",
    "plt.title('Scatter Plot: Tenure in Months vs Total Revenue')\n",
    "plt.show\n",
    "\n",
    "#3. Total Charges & Tenure in Months (0.83)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x = 'Total Charges', y = 'Tenure in Months')\n",
    "plt.title('Scatter Plot: Total Charges vs Tenure in Months')\n",
    "plt.show\n",
    "\n",
    "#4. Total Long Distance Charges & Total Revenue (0.78)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x = 'Total Long Distance Charges', y = 'Total Revenue')\n",
    "plt.title('Scatter Plot: Total Long Distance Charges vs Total Revenue')\n",
    "plt.show\n",
    "\n",
    "#5. Total Long Distance Charges & Tenure in Months (0.67)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x = 'Total Long Distance Charges', y = 'Tenure in Months')\n",
    "plt.title('Scatter Plot: Total Long Distance Charges vs Tenure in Months')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop('Customer Status', axis=1) # X contains features\n",
    "\n",
    "#Drop non-numeric features\n",
    "X = X.select_dtypes(include=['int64', 'float64']) # select numeric features\n",
    "X['Gender'] = data['Gender']\n",
    "X['Married'] = data['Married']\n",
    "\n",
    "y = data['Customer Status'] # y contains target\n",
    "\n",
    "# Split data into 80/20 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "# Check sizes of training and testing sets\n",
    "print(\"Training set size: \", len(X_train))\n",
    "print(\"Testing set size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "binary_features = ['Gender', 'Married']\n",
    "#multi_class_features = ['Payment Method', 'Churn Category']\n",
    "\n",
    "# Label encoding for binary features\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in binary_features:\n",
    "    X_train[feature] = label_encoder.fit_transform(X_train[feature])\n",
    "    X_test[feature] = label_encoder.transform(X_test[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target feature\n",
    "encoder_y = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform on the training data\n",
    "y_train_encoded = encoder_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Transform the test data using the same encoder and handle unknown categories\n",
    "y_test_encoded = encoder_y.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns # to exclude catergorical/non-numeric features from scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy() # make a copy of X_train to avoid modifying original data\n",
    "X_train_scaled[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values \n",
    "missing_values = X_train_scaled.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Impute 'Avg Monthly Long Distance Charges' & 'Avg Monthly GB Download'\n",
    "imputer = SimpleImputer(strategy= 'mean')\n",
    "columns_to_impute = [\"Avg Monthly Long Distance Charges\", \"Avg Monthly GB Download\"]\n",
    "\n",
    "X_train_scaled[columns_to_impute] = imputer.fit_transform(X_train_scaled[columns_to_impute])\n",
    "X_test_scaled[columns_to_impute] = imputer.transform(X_test_scaled[columns_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Build Model \n",
    "The Random Forest Model is a robust ensemble learning algorithm that works well for classification tasks like churn prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initialise model \n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth= 10, min_samples_split= 2, random_state = 42)\n",
    "\n",
    "# Train the model (fit)\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the lables on the test set \n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Matrix Confusion\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix: \", conf_mat)\n",
    "\n",
    "# Classification Report \n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report: \", class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "838d971102262dd57cf08ac3a7b1dc6b4d83ecc4a27e122841ac1146d2e45644"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
